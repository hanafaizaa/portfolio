library(ggplot2)
library(dplyr)
library(tidyr)
library(factoextra)
data <- read.csv("C:/Users/hanfai/portfolio/clustering/Data Mall_Customer.csv", sep = ";")
head(data)
model <- keras_model_sequential() %>%
layer_dense(units = 100, activation = "relu", input_shape = ncol(train_X)) %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 1, activation = "linear")
# Penyiapan Data
library(readr)
dt <- read.csv("C:/Users/hanfai/portfolio/artificial neural network/data ann.csv")
head(dt)
colSums(is.na(dt)) # untuk memeriksa missing value
# Partisi data: data dibagi dengan proporsi 0.7 untuk data latih dan 0.3 untuk data uji
library(caret)
set.seed(123)
train.index <- createDataPartition(dt$rate, p = 0.7, list = FALSE)
train <- dt[train.index, ]
test <- dt[-train.index, ]
# Standardisasi data: standardisasi data dilakukan karena setiap peubah memiliki skala atau peubah yang berbeda.
preprocessParams <- preProcess(train[, -6], method=c("range"))
train_X <- as.matrix(predict(preprocessParams, train[, -6]))
test_X <- as.matrix(predict(preprocessParams, test[, -6]))
train_y <- train[, 6]
test_y <- test[, 6]
library(keras)
library(tensorflow)
library(dplyr)
model <- keras_model_sequential() %>%
layer_dense(units = 100, activation = "relu", input_shape = ncol(train_X)) %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 1, activation = "linear")
install_tensorflow()
library(tensorflow)
install_tensorflow()
library(reticulate)
py_config()
use_python("path/to/python", required = TRUE)
model <- keras_model_sequential() %>%
layer_dense(units = 100, activation = "relu", input_shape = ncol(train_X)) %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 1, activation = "linear")
model <- keras_model_sequential() %>%
layer_dense(units = 100, activation = "relu", input_shape = ncol(train_X)) %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 1, activation = "linear")
use_virtualenv("path/to/virtualenv", required = TRUE)
library(reticulate)
virtualenv_create("r-reticulate")
virtualenv_install("r-reticulate", "tensorflow")
model <- keras_model_sequential() %>%
layer_dense(units = 100, activation = "relu", input_shape = ncol(train_X)) %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 1, activation = "linear")
