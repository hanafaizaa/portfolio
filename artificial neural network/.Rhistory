knitr::opts_chunk$set(echo = TRUE)
dt <- read.csv("C:/Users/hanfai/portfolio/artificial neural network/data ann.csv")
head(dt)
library(tensorflow)
library(dplyr)
model <- keras_model_sequential() %>%
layer_dense(units = 100, activation = "relu", input_shape = ncol(train_X)) %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 1, activation = "linear")
library(keras)
library(tensorflow)
library(dplyr)
model <- keras_model_sequential() %>%
layer_dense(units = 100, activation = "relu", input_shape = ncol(train_X)) %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 1, activation = "linear")
model <- keras_model_sequential() %>%
layer_dense(units = 100, activation = "relu", input_shape = ncol(train_X)) %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 1, activation = "linear")
model <- keras_model_sequential() %>%
layer_dense(units = 100, activation = "relu", input_shape = ncol(train_X)) %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 1, activation = "linear")
# Penyiapan Data
library(readr)
dt <- read.csv("C:/Users/hanfai/portfolio/artificial neural network/data ann.csv")
head(dt)
colSums(is.na(dt)) # untuk memeriksa missing value
# Partisi data: data dibagi dengan proporsi 0.7 untuk data latih dan 0.3 untuk data uji
library(caret)
set.seed(123)
train.index <- createDataPartition(dt$rate, p = 0.7, list = FALSE)
train <- dt[train.index, ]
test <- dt[-train.index, ]
# Standardisasi data: standardisasi data dilakukan karena setiap peubah memiliki skala atau peubah yang berbeda.
preprocessParams <- preProcess(train[, -6], method=c("range"))
train_X <- as.matrix(predict(preprocessParams, train[, -6]))
test_X <- as.matrix(predict(preprocessParams, test[, -6]))
train_y <- train[, 6]
test_y <- test[, 6]
# Pemodelan dengan NN
library(keras)
library(tensorflow)
library(dplyr)
model <- keras_model_sequential() %>%
layer_dense(units = 100, activation = "relu", input_shape = ncol(train_X)) %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 1, activation = "linear")
model <- keras_model_sequential() %>%
layer_dense(units = 100, activation = "relu", input_shape = ncol(train_X)) %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 1, activation = "linear")
# Kompilasi Model
model %>% compile(
loss = "mean_squared_error",
optimizer = "adam",
metrics = list("mean_squared_error", "mean_absolute_error")
)
# Penyiapan Data
library(readr)
dt <- read.csv("C:/Users/hanfai/portfolio/artificial neural network/data ann.csv")
head(dt)
colSums(is.na(dt)) # untuk memeriksa missing value
# Partisi data: data dibagi dengan proporsi 0.7 untuk data latih dan 0.3 untuk data uji
library(caret)
set.seed(123)
train.index <- createDataPartition(dt$rate, p = 0.7, list = FALSE)
train <- dt[train.index, ]
test <- dt[-train.index, ]
# Standardisasi data: standardisasi data dilakukan karena setiap peubah memiliki skala atau peubah yang berbeda.
preprocessParams <- preProcess(train[, -6], method=c("range"))
train_X <- as.matrix(predict(preprocessParams, train[, -6]))
test_X <- as.matrix(predict(preprocessParams, test[, -6]))
train_y <- train[, 6]
test_y <- test[, 6]
# Pemodelan dengan NN
library(keras)
library(tensorflow)
library(dplyr)
model <- keras_model_sequential() %>%
layer_dense(units = 100, activation = "relu", input_shape = ncol(train_X)) %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 100, activation = "relu") %>%
layer_dropout(0.3) %>%
layer_dense(units = 1, activation = "linear")
# Kompilasi Model
model %>% compile(
loss = "mean_squared_error",
optimizer = "adam",
metrics = list("mean_squared_error", "mean_absolute_error")
)
